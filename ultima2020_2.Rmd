<center><img src="https://github.com/PoliticayGobiernoPUCP/estadistica_anapol2/raw/master/PICS/LOGO_PUCP.png" width="500"></center>

<center> <header><h1>ESTADISTICA PARA EL ANALISIS POLITICO II</h1>  </header></center>

* Profesor:  <a href="http://www.pucp.edu.pe/profesor/jose-manuel-magallanes/" target="_blank">Dr. José Manuel Magallanes, Ph.D.</a> <br>
    - Profesor del Departamento de Ciencias Sociales, Sección de Ciencia Política y Gobierno.
    - [Oficina 105](https://goo.gl/maps/xuGeG6o9di1i1y5m6) - Edificio CISEPA / ECONOMIA / CCSS
    - Telefono: (51) 1 - 6262000 anexo 4302
    - Correo Electrónico: [jmagallanes@pucp.edu.pe](mailto:jmagallanes@pucp.edu.pe)
    

____

<center> <header><h2>Sesión de cierre 2020 II</h2>  </header></center>
____

Esta sesión está pensada en tu test teórico y en tu proyecto final, por lo que la he redactado integrando diversos componentes del curso que hemos compartido.

## La data

Si uds trabajan en grupo lo promero que deben haber hecho es preguntarse por como el comportamiento de una variable (la dependiente) puede explicarse, en parte, por el comportamiento de otra(s) (la(s) independientes). De ahí, revisas diversos trabajos de investigación que te permiten hipotetizar esa relación. Cuando lo tienes en claro, vas por la data que operacionalice tal hipotesis.

Si me pregunto: ¿Qué explica el nivel felicidad?, luego leo y encuentro que la democracia puede influir en la felicidad, me animo a hipotetizar que la democracia influye en la felicidad. Al buscar la data, encuentro que hay data a nivel de país (país será la unidad de análisis). Estas datas ya son archiconocidas por ti:


* [https://en.wikipedia.org/wiki/World_Happiness_Report](https://en.wikipedia.org/wiki/World_Happiness_Report)

* [https://en.wikipedia.org/wiki/Democracy_Index](https://en.wikipedia.org/wiki/Democracy_Index)

Traigamamos la data:

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
library(htmltab)

# creo una "vector" con "nombres" para los links: 
happyInfo=c(url="https://en.wikipedia.org/wiki/World_Happiness_Report",
        path='//*[@id="mw-content-text"]/div/table/tbody')
demoInfo=c(url="https://en.wikipedia.org/wiki/Democracy_Index", 
       path='//*[@id="mw-content-text"]/div/table[2]/tbody')

# carga
happy = htmltab(doc = happyInfo["url"],which  = happyInfo["path"])
demo  = htmltab(doc = demoInfo["url"],which  = demoInfo["path"])
```

## El preprocesamiento

Nuestra data seguro necesitara algo de pre procesamiento, por lo que luego de ver los nombres (names()) y la estructura (str()) será mejor asegurarnos que nos quedemos con lo que corresponda:
```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}

# Que no haya espacios en blanco al inicio ni al fin de las celdas
happy[,]=lapply(happy[,], trimws,whitespace = "[\\h\\v]") 
demo[,]=lapply(demo[,], trimws,whitespace = "[\\h\\v]") 

# nombres sin espacios en blanco
library(stringr)
names(happy)=str_split(names(happy)," ",simplify = T)[,1]
names(demo)=str_split(names(demo)," ",simplify = T)[,1]

#nombres de variables solo letras (usar con cuidado)
names(demo)=gsub(pattern = "\\W",replacement = "",x = names(demo))


# Eliminemos columnas que no usaremos esta vez:
happy$Overall=NULL
demo$Rank=NULL
demo$Changes=NULL


# Asegurando tipo de variable es el adecuado:

## En demo:
demo[,2:7]=lapply(demo[,2:7],as.numeric)

# En happy:
happy[,-1]=lapply(happy[,-1],as.numeric)


```

## La integración

Tener dos indicadores con sus componentes es lo que cada uno de los miembros del grupo debe haber aportado al trabajo. Luego del paso anterior, cada miembro del grupo debe tener su data lista, pero ahora hay que integrarla:

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
# como ambas tiene una columna 'Score', hay que renombrar
names(happy)[names(happy)=="Score"]="ScoreHappy"
names(demo)[names(demo)=="Score"]="ScoreDemo"
#ahora sí:
HappyDemo=merge(happy,demo)
```

Hemos perdido países en el merge, en tu trabajo final debes recuperar la mayor cantidad de casos.

Hasta aquí, ya podrías hacer una regresión, para probar tu hipotesis, usando los 'scores':

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
hipotesis1=formula(ScoreHappy~ScoreDemo)
regresion1=lm(hipotesis1,data=HappyDemo)

#encontrando:
summary(regresion1)
```
De lo anterior, puedes ver que se cumple que hay relación **significativa** (p-value del F-statistic). Esa relación es directa: "a mayor democracia, mayor felicidad". Puede inclusive proponer que si el nivel de democracia aumenta en un punto, el nivel de felicidad aumenta en 0.31670, con una significancia del 0.001. 

## Calculando tus latentes

En vez de usar los scores, usemos analisis factorial. Vayamos por el camino exploratorio: "¿Habrá conjuntos de variables que representen algun concepto?". Nótese que las variables medidas para democracia están en una misma "escala" (del 0 al 10), pero que para el caso de felicidad usaremos un conjunto de variables que no se usan para su construcció pero que están relacionadas con la felicidad.

El primer paso es examinar la matriz de correlaciones:
```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
theData=HappyDemo[,c(3:8,10:14)]

#matriz de correlaciones
library(polycor)
corMatrix=polycor::hetcor(theData)$correlations
```

Una vez calculada la matriz, verificamos si el analisis factorial será util dados los datos  disponibles (por convención del curso asumiremos que podemos continuar si el MSA > 0.6):

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
library(psych)
KMO(corMatrix)$MSA
```

Para ver como cada variable contribuye al "adequacy":

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
KMO(corMatrix)$MSAi
```
Hasta aquí parece que todo está bien, aunque una variable podría dar problemas (*Generosity*). Sólo falta confirmar que la matriz de correlación cumple los dos requisitos solicitados:

* Hnula: La matriz de correlacion es una [matriz identidad](https://en.wikipedia.org/wiki/Identity_matrix)

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
cortest.bartlett(corMatrix,n=nrow(theData))$p.value>0.05
```

* Hnula: La matriz de correlacion es una [matriz singular](http://mathworld.wolfram.com/SingularMatrix.html).

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
#instalaste "matrixcalc'?
matrixcalc::is.singular.matrix(corMatrix)
```

Por teoría podríamos asumir que hay dos latentes, pero sigamos explorando cuantas sugiere esta técnica:
```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
#instalar 'parameters' y 'n_factors'
sugerencia=parameters::n_factors(corMatrix)

#instalar 'see'
# tenemos:
plot(sugerencia)
```

No nos sugieren 2, sino 3 latentes. Veamos cuales son:

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
# instalaste "GPArotation"?
library(GPArotation)
resfa <- fa(theData,
            nfactors = 3,
            rotate = "varimax")

fa.diagram(resfa)
```
Vemos que una latente corresponde a la latente de democracia, mientras que las que hemos asumido representan la felicidad no se agrupa en una sola. Si puedes sustentar una modificación a tu hipotesis, es el momento de revisar tu teoría, aquí en particular el concepto de felicidad.

Planteemos el siguiente cambio, que felicidad es el MR3, y ahora revisas tu teoría y vez si se puede sustentar la existencia de la "tranquilidad", que sería la MR2 (¿y que tal si descartabas las variables de MR2?). Si aplicamos las evaluaciones a este EFA, vemos que hay cierto sustento para mantenerlo. 

## Regresion usando el camino de las latentes:

Planteemos nuestra regresión usando SEM (structural equation model). SEM hace un trabajo doble, calcula las latentes usando CFA, y lleva a cabo a regresion con las variables latentes (y otras no latentes si hubieran). El primer paso es asegurarse que la data este en la misma escala:
```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
HappyDemoScaled=scale(HappyDemo[,-c(1,2,9,15:16)])
```


Luegp, en formato TEXTO (entre comillas) se **describe** el modelo (teoria) a probar con las latentes y la regresión. Por ejemplo, una latente como *felicidad*, se construye a partir de *GDP + Social + Healthy* usando el simbolo **$=\sim$**. La regresion luego conectara variables dependiente a independientes con **$\sim$**, veamos:

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}

model <- '# describiendo las latentes:
          democracia  =~ Electoral + Functioning + Politicalparticipation + Politicalculture + Civilliberties
           tranquilidad =~ Freedom + Generosity + Perceptions
           felicidad   =~ GDP + Social + Healthy
           
         # regresion con las latentes:
         felicidad~tranquilidad + democracia'
```

Ya con el modelo definido, testeas todo:

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
#instalaste "lavaan"?
library(lavaan)
fit <- sem(model, data=HappyDemoScaled)
```

Todo se ha guardado en **fit**. Primero recupero los parametros estimados: 

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
# conseguir los parametros
allParamSEM=parameterEstimates(fit,standardized = T)

```

Así, podemos ver los resultados de la regresion:

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
allParamSEM[allParamSEM$op=="~",]
```

Eses resultado se interpreta igual que cuando hicimos regresion con *lm*, aunque veremos luego que no saldrá lo mismo.

En este punto, debemos evaluar todo el SEM, usemos la función *fitMeasures*:
```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
# conseguir las medidas de evaluación
allFitSEM=as.list(fitMeasures(fit))
```

* Test 1: El ChiSquare es NO significativo? (queremos que NO lo sea)

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}

allFitSEM[c("chisq",  "pvalue")] # pvalue>0.05
```

No pasó .

* Test 2: El Índice Tucker Lewis es mayor a 0.9? (queremos que sea mayor).

```{r,echo=TRUE}
allFitSEM$tli # > 0.90
```
No pasó.

* La Raíz del error cuadrático medio de aproximación es menor a 0.05?

```{r,echo=TRUE}
allFitSEM[c('rmsea.ci.lower','rmsea' ,'rmsea.ci.upper')] 
```

Tampoco pasó, pues 0.05 es menor que el **rmsea.ci.lower**, y debería ser mayor que el **rmsea.ci.upper**.

A esta altura, ya sabemos que el SEM en su totalidad nos informa que aun cuando por partes parece haber correspondencias, en su totalidad la teoría planteada tiene problemas para ser generalizada con la data disponible.


Con **lavPredict()** podemos calcular las latentes, y podemos luego añadirlas a la data original:

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
HappyDemo=as.data.frame(cbind(HappyDemo,lavPredict(fit)))
```

Las latentes tienen valores muy diferentes a los de los scores, pero podemos transformarlos a ese rango:
```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
library(BBmisc)

# el rango nuevo usara como minimo y maximo los valores del Score que vino con la data (eso lo hago con min y max):
HappyDemo$tranquilidad=normalize(HappyDemo$tranquilidad , 
                       method = "range", 
                       margin=2, # by column
                       range = c(min(HappyDemo$ScoreHappy),
                                 max(HappyDemo$ScoreHappy)))

HappyDemo$felicidad=normalize(HappyDemo$felicidad, 
                       method = "range", 
                       margin=2, # by column
                       range = c(min(HappyDemo$ScoreHappy),
                                 max(HappyDemo$ScoreHappy)))

HappyDemo$democracia=normalize(HappyDemo$democracia, 
                       method = "range", 
                       margin=2, # by column
                       range = c(min(HappyDemo$ScoreDemo),
                                 max(HappyDemo$ScoreDemo)))

```

Veamos un resumen estadistico:
```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
summary(HappyDemo)
```

En SEM la regresión salió bien; ahora que cuento con las latentes puedo correr la regresión con el metodo clásico:

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
summary(lm(felicidad~tranquilidad+democracia,
           data = HappyDemo))
```

Esto no contradice al SEM, pero no tiene la información que SEM tenía, aqui la funcion **lm** no sabe que está usando latentes. Correr un SEM es mejor que usar regresion lineal ante la presencia de latentes y cuando queremos probar TODO en simultaneo. Esto es muy exigente, y lo visto aquí es sólo muy poco del tema.

Veamos visualmente los scores originales y los calculados con SEM, pues debería haber correlación:

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
library(ggplot2)
library(ggpubr)
p1=ggscatter(HappyDemo, 
          x = "democracia", y = "ScoreDemo",
          cor.coef = TRUE, 
          cor.method = "pearson") # spearman?

p2=ggscatter(HappyDemo, 
          x = "tranquilidad", y = "ScoreHappy",
          cor.coef = TRUE, 
          cor.method = "pearson") 

p3=ggscatter(HappyDemo, 
          x = "felicidad", y = "ScoreHappy",
          cor.coef = TRUE, 
          cor.method = "pearson") 

ggarrange(p1, p2, p3, 
          ncol = 3)
```

## Usando clusters

Podria usar clusters en la regresión? Me puede servir para crear una ordinal:

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
set.seed(123)
# creemos clusters con las variable relacionadas con felicidad
library(cluster)
dist=daisy(HappyDemo[,3:8],stand = T)
res.pam=pam(x=dist,diss = T,k=3)
HappyDemo$pamhappy=res.pam$clustering

```
Verifiquemos cómo rankea  el valor del cluster:
```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
aggregate(ScoreHappy~pamhappy,data = HappyDemo,FUN = mean)
```

Verificamos que la etiqueta no requiere recodificar, pues va como ascendente. Continuamos:

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
#como ordinal!
HappyDemo$pamhappy=as.ordered(HappyDemo$pamhappy)
#usemos regresión para otra hipotesis:
hipotesis2=formula(ScoreDemo~pamhappy)

# regresion
regresion2=lm(hipotesis2,data=HappyDemo)
summary(regresion2)
```
Observa que el efecto lineal (pamhappy.L) es significativo, pero el cuadrático no lo es (pamhappy.Q). El lineal nos importará, pues quiere decir el efecto de pasar del nivel 1 al 2, y del 2 al 3. Esto sugiere que si un país esta en el grupo 1 de felicidad, su indice de democracia en *promedio* sube en 2.49 si llega a subir al nivel 2 de felicidad (lo mismo puedes decir si pasa del 2 al 3).


## Y si mi dependiente es categórica?

Cuando la independiente es categórica, hacemos uso de la regresión logística. Veamos sólo el caso con dependiente dicotómica.

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
# es feliz?
HappyDemo$esfeliz=HappyDemo$felicidad>median(HappyDemo$felicidad)
```

La nueva variable es dicotomica:
```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
table(HappyDemo$esfeliz)
```
Apliquemos la regresión logística, utilizando las latentes calculadas (menos felicidad):
```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}

hipotesis3=formula(esfeliz~democracia + tranquilidad)
regresion3=glm(hipotesis3, data=HappyDemo,family = binomial)

#resultado clásico:
summary(regresion3)

```

Vemos que la *tranquilidad* y la *democracia* afectan la probabilidad que un país sea *feliz* (ambas son significativas y tiene efecto positivo). A diferencia de la regresión lineal, no podemos dar una interpretación en lenguaje sencillo a esos coeficientes.

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
# interpracion usando marginal effects:
library(margins)
# 
(model = margins(regresion3))
```
Esto quiere decir en cuanto las variables afectan a la probabilidad de ser feliz, por ejemplo, cada vez que la democracia sube un punto, la probabilidad que un país sea feliz se eleva en 0.1 (10%).



