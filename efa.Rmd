<center><img src="https://github.com/PoliticayGobiernoPUCP/estadistica_anapol2/raw/master/PICS/LOGO_PUCP.png" width="500"></center>

<center> <header><h1>ESTADISTICA PARA EL ANALISIS POLITICO II</h1>  </header></center>

* Profesor:  <a href="http://www.pucp.edu.pe/profesor/jose-manuel-magallanes/" target="_blank">Dr. José Manuel Magallanes, Ph.D.</a> <br>
    - Profesor del Departamento de Ciencias Sociales, Sección de Ciencia Política y Gobierno.
    - [Oficina 105](https://goo.gl/maps/xuGeG6o9di1i1y5m6) - Edificio CISEPA / ECONOMIA / CCSS
    - Telefono: (51) 1 - 6262000 anexo 4302
    - Correo Electrónico: [jmagallanes@pucp.edu.pe](mailto:jmagallanes@pucp.edu.pe)
    

____

<center> <header><h2>Análisis Factorial I: Exploración</h2>  </header></center>
____

Hacemos analisis factorial para reducir las **variables** en otras variables resumen. Mientras la clusterización agrupaba filas, la factorización agrupa columnas. Pero, al igual que en clusterización, queremos saber si las nuevas variables tienen un _nombre_, al cual se le denomina técnicamente _variable latente_. En esta sesión exploraremos la data a ver qué  emerge.  

## Preparación de Datos:

Para esta sesión trabajaremos con la data de estos links:


* [https://en.wikipedia.org/wiki/World_Happiness_Report](https://en.wikipedia.org/wiki/World_Happiness_Report)

* [https://en.wikipedia.org/wiki/Democracy_Index](https://en.wikipedia.org/wiki/Democracy_Index)


```{r, echo=FALSE, eval=TRUE,warning=FALSE, message=FALSE}
library(htmltab)

# links
happyL=c("https://en.wikipedia.org/wiki/World_Happiness_Report",
         '//*[@id="mw-content-text"]/div/table/tbody')
demoL=c("https://en.wikipedia.org/wiki/Democracy_Index", 
        '//*[@id="mw-content-text"]/div/table[2]/tbody')

# carga
happy = htmltab(doc = happyL[1],which  = happyL[2],encoding = "UTF-8")
demo  = htmltab(doc = demoL[1], which  = demoL[2], encoding = "UTF-8")

# limpieza

happy[,]=lapply(happy[,], trimws,whitespace = "[\\h\\v]") # no blanks
demo[,]=lapply(demo[,], trimws,whitespace = "[\\h\\v]") # no blanks

library(stringr) # nombres simples
names(happy)=str_split(names(happy)," ",simplify = T)[,1]
names(demo)=str_split(names(demo)," ",simplify = T)[,1]

```

Veamos que tenemos:
```{r}
str(demo)
```

```{r}
str(happy)
```

Eliminemos columnas que no usaremos esta vez:
```{r}
happy$Overall=NULL
demo[,c(1,9,10)]=NULL
```

También debemos tener nombres diferentes en los scores antes del merge:
```{r}
names(happy)[names(happy)=="Score"]="ScoreHappy" 
names(demo)[names(demo)=="Score"]="ScoreDemo"
```

Tenemos:
```{r}
str(demo)
```

```{r}
str(happy)
```


Y ahora arreglemos el tipo de variables:

* En demo:

```{r}
demo[,-c(1)]=lapply(demo[,-c(1)],as.numeric)

```

* En happy:

```{r}
happy[,-c(1)]=lapply(happy[,-c(1)],as.numeric)
```

Eliminemos al perdidos al perdido:

```{r}
happy=na.omit(happy)
```

** Presta atención al merge**. Usualmente hacemos merge por _default_ y luego perdemos varias filas:

```{r}
nrow(merge(happy,demo))
```

Hagamos un **nuevo** merge, donde veamos **TODO**:

```{r}
HappyDemo=merge(happy,demo,all.x=T, all.y=T)
```

Esta vez HappyDemo tiene varios paises de más, pero con valores perdidos y nombres que no pudieron coincidir. Veamos:

```{r}
HappyDemo[!complete.cases(HappyDemo),]
```

De lo anterior date cuenta que, por un lado, hay paises que les falta un bloque de indicadores, y que en muchos casos los nombres están mal escritos. Podemos recuperar algunos, pero su data original:


```{r}
# cambiemos a nombres mas sencillos:
## en demo
demo[demo$Country=="Democratic Republic of the Congo",'Country']="Congo (Kinshasa)"
demo[demo$Country=="Republic of the Congo",'Country']="Congo (Brazzaville)"
demo[demo$Country=="Trinidad and Tobago",'Country']="Trinidad & Tobago"
demo[demo$Country=="North Macedonia",'Country']="Macedonia"

## en happy
happy[happy$Country=="Palestinian Territories",'Country']="Palestine"

```

Luego de esos ajustes veamos:

```{r}
HappyDemo=merge(happy,demo) # re creando HappyDemo
nrow(HappyDemo)
```

En efecto se recuperaron 5 paises, asi quedará.

## Evaluando data

El análisis factorial requiere que hagamos algunas observaciones previas.

1. Calculemos matriz de correlación:
```{r}

theData=HappyDemo[,-c(1,2,9)] # sin los Scores ni nombre de país.

# esta es:
library(polycor)
corMatrix=polycor::hetcor(theData)$correlations
```

2. Explorar correlaciones:

* Sin evaluar significancia:
```{r}
library(ggcorrplot)

ggcorrplot(corMatrix)
```

* Evaluando significancia:

```{r}
ggcorrplot(corMatrix,
          p.mat = cor_pmat(corMatrix),
          insig = "blank")
```

3. Verificar si datos permiten factorizar:

```{r}
library(psych)
psych::KMO(corMatrix) 
```

4. Verificar si la matriz de correlaciones es adecuada

* Hnula: La matriz de correlacion es una matriz identidad

```{r}
cortest.bartlett(corMatrix,n=nrow(theData))$p.value>0.05
```

* Hnula: La matriz de correlacion es una matriz singular

```{r}
library(matrixcalc)

is.singular.matrix(corMatrix)
```

5. Determinar en cuantos factores o variables latentes podríamos redimensionar la data:

```{r}
fa.parallel(theData,fm = 'ML', fa = 'fa')
```

Se sugieren 3, veamos.


6. Redimensionar a numero menor de factores

* Resultado inicial:

```{r}
library(GPArotation)
resfa <- fa(theData,nfactors = 3,cor = 'mixed',rotate = "varimax",fm="minres")
print(resfa$loadings)
```

* Resultado mejorado:

```{r}
print(resfa$loadings,cutoff = 0.51)
```

Cuando logramos que cada variable se vaya a un factor, tenemos una _estructura simple_.

* Resultado visual:

```{r}
fa.diagram(resfa)
```

7. Evaluando Resultado obtenido:

```{r}
summary(resfa)
```

* La Raíz del error cuadrático medio corregida está cerca a cero?
```{r}
resfa$crms
```

* La Raíz del error cuadrático medio de aproximación es menor a 0.05?

```{r}
resfa$RMSEA
```

* El índice de Tucker-Lewis es mayor a 0.9:

```{r}
resfa$TLI
```

8. Posibles valores proyectados:

¿Qué nombres les darías?

```{r}
as.data.frame(resfa$scores)
```

```{r, fig.width=8, fig.height=8}

HappyDemoFA=cbind(HappyDemo[1],as.data.frame(resfa$scores))

library(plotly)


plot_ly(data=HappyDemoFA, x = ~MR1, y = ~MR2, z = ~MR3, text=~Country) %>%
  add_markers() %>%
  layout(scene = list(xaxis = list(title = 'Demo'),
                     yaxis = list(title = 'Tranquilidad'),
                     zaxis = list(title = 'Bienestar')))

```


RECORDANDO:


```{r}
library(fpc)
library(cluster)
library(dbscan)

# YA NO NECESITAS CMD para HappyDemoFA[,c(2:4)]

g.dist.cmd = daisy(HappyDemoFA[,c(2:4)], metric = 'euclidean')
kNNdistplot(g.dist.cmd, k=3)
```

Para tener una idea de cada quien:

```{r}
resDB=fpc::dbscan(g.dist.cmd, eps=0.6, MinPts=3,method = 'dist')
HappyDemoFA$clustDB=as.factor(resDB$cluster)
aggregate(cbind(MR1, MR2,MR3) # dependientes
          ~ clustDB, # nivel
          data = HappyDemoFA,    # data
          max)            # operacion
```

```{r, fig.width=8, fig.height=8}

plot_ly(data=HappyDemoFA, x = ~MR1, y = ~MR2, z = ~MR3, text=~Country, color = ~clustDB) %>%
  add_markers() %>%
  layout(scene = list(xaxis = list(title = 'Demo'),
                     yaxis = list(title = 'Tranquilidad'),
                     zaxis = list(title = 'Bienestar')))

```




_____
<br></br>

[al INICIO](#beginning)

[VOLVER A CONTENIDOS](https://politicaygobiernopucp.github.io/estadistica_anapol2/)
