---
output:
  pdf_document: default
  html_document: default
---
<center><img src="https://github.com/PoliticayGobiernoPUCP/estadistica_anapol2/raw/master/PICS/LOGO_PUCP.png" width="500"></center>

<center> <header><h1>ESTADISTICA PARA EL ANALISIS POLITICO II</h1>  </header></center>

* Profesor:  <a href="http://www.pucp.edu.pe/profesor/jose-manuel-magallanes/" target="_blank">Dr. José Manuel Magallanes, Ph.D.</a> <br>
    - Profesor del Departamento de Ciencias Sociales, Sección de Ciencia Política y Gobierno.
    - [Oficina 105](https://goo.gl/maps/xuGeG6o9di1i1y5m6) - Edificio CISEPA / ECONOMIA / CCSS
    - Telefono: (51) 1 - 6262000 anexo 4302
    - Correo Electrónico: [jmagallanes@pucp.edu.pe](mailto:jmagallanes@pucp.edu.pe)
    

____

<center> <header><h2>Análisis de Conglomerados: Estrategia de Jerarquizacion</h2>  </header></center>
____

<a id='beginning'></a>

La jerarquización busca clusterizar por etapas, hasta que todas las posibilidades de clusterizacion sean visible. Este enfoque tiene dos familias de algoritmos:

* [Aglomerativos](#agg)
* [Divisivos](#div)


Aquí hay un resumen breve del tema:

<iframe width="800" height="600" src="https://www.youtube.com/embed/d1teghNuOu8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

Traigamos nuevamente la data del _Democracy Index_:

```{r, warning=FALSE, message=FALSE, warning=FALSE, message=FALSE}
# coleccion
library(htmltab)
demolink = "https://en.wikipedia.org/wiki/Democracy_Index"
demopath = '//*[@id="mw-content-text"]/div/table[2]/tbody'
demo<- htmltab(doc = demolink, which =demopath)

# limpieza
library(stringr)
library(magrittr)
names(demo)=str_split(names(demo),">>",simplify = T)[,1]%>%gsub('\\s','',.)

demo[,-c(1,8,9)]=lapply(demo[,-c(1,8,9)], trimws,whitespace = "[\\h\\v]") # no blanks

# preparación
demo=demo[,-c(1)] #sin Rank
demo[,-c(1,8,9)]=lapply(demo[,-c(1,8,9)], as.numeric) # a numerico


# veamos que tenemos:
str(demo)
```

<a id='agg'></a>

## <font color="red">Estrategia Aglomerativa</font>


En esta estrategia se parte por considerar cada caso (fila) como un cluster, para de ahi ir creando miniclusters hasta que todos los casos sean un solo cluster. El proceso va mostrando que tanto _esfuerzo_ toma juntar los elementos cluster tras cluster.



Antes de proseguir, nos aseguramos que:

* Los nombres de cada caso aparezcan en las gráficas:
```{r, warning=FALSE, message=FALSE, warning=FALSE, message=FALSE}
row.names(demo)=demo$Country
```

* Solo trabajemos con data sin valores perdidos:

```{r, warning=FALSE, message=FALSE, warning=FALSE, message=FALSE}
# alternativa a complete.cases:
demo=na.omit(demo)
```

Ahora podemos continuar:

### 1. Calcular distancias

El primer paso es calcular distancias:

```{r, warning=FALSE, message=FALSE, warning=FALSE, message=FALSE, warning=FALSE, message=FALSE}
library(cluster)

g.dist = daisy(demo[,c(3:7)], metric="gower")
```

### 2. Decidir _linkages_

Esta es la distancia entre los elementos, tenemos que decidir como se irá calculando la distancia entre los clusters que se van formando (ya no son casos individuales). Los tres mas simples metodos:

* Linkage tipo <a href="https://www.youtube.com/embed/RdT7bhm1M3E" target="_blank">SINGLE</a>.

* Linkage tipo <a href="https://www.youtube.com/embed/Cy3ci0Vqs3Y" target="_blank">COMPLETE</a>.

* Linkage tipo <a href="https://www.youtube.com/embed/T1ObCUpjq3o" target="_blank">AVERAGE</a>


Otro metodo adicional, y muy eficiente, es el de **Ward**. Al final, lo que necesitamos saber cual de ellos nos entregará una mejor propuesta de clusters. Usemos este para nuestro caso.


### 3. Calcular clusters

La función **hcut** es la que usaremos para el método jerarquico, y el algoritmo aglomerativo se emplea usando **agnes**. El linkage será **ward** (aquí _ward.D_):

```{r, warning=FALSE, message=FALSE, warning=FALSE, message=FALSE}

library(factoextra)

res.agnes<- hcut(g.dist, k = 4,hc_func='agnes',hc_method = "ward.D")

demo$clustAG=res.agnes$cluster

```



### 4. Comparar

Veamos qué tanto se parece a la clasificación de _The Economist_:

```{r, warning=FALSE, message=FALSE, warning=FALSE, message=FALSE}
table(demo$Regimetype,demo$clustAG,dnn = c('TheEconomist','clustAgg'))
```


### 5. Visualizar

El **dendograma** nos muestra el proceso de conglomeración:

```{r, fig.width=20, fig.height=20 , warning=FALSE, message=FALSE, warning=FALSE, message=FALSE}
# Visualize
fviz_dend(res.agnes,k=4, cex = 0.7, horiz = T)
```

El eje 'Height' nos muestra el "costo" de conglomerar.


____

<a id='div'></a>

## <font color="red">Estrategia Divisiva</font>


Esta estrategia comienza con todos los casos como un gran cluster; para de ahi dividir en clusters más pequeños. Comparando con el proceso anterior, el paso 1 no es necesario repetirlo, el paso 2 no corresponde a esta técnica, por lo que vamos directo al paso 3:

### 3. Calcular clusters


La función **hcut** es la que usaremos para el método jerarquico, y el algoritmo divisivo se emplea usando **diana**:


```{r, warning=FALSE, message=FALSE, warning=FALSE, message=FALSE}
res.diana <- hcut(g.dist, k = 4,hc_func='diana')
demo$clustDIV=res.diana$cluster
```


### 4. Comparar

Veamos qué tanto se parece a la clasificación de _The Economist_:


```{r, warning=FALSE, message=FALSE, warning=FALSE, message=FALSE}
table(demo$Regimetype,demo$clustDIV,dnn = c('TheEconomist','clustDiv'))
```

### 5. Visualizar

El **dendograma** nos muestra el proceso de conglomeración:


```{r, fig.width=20, fig.height=20, warning=FALSE, message=FALSE, warning=FALSE, message=FALSE}
fviz_dend(res.diana, cex = 0.7,horiz = T)
```

Nota que en esta técnica se ve a todos los elementos (casos) asignados a algun cluster. 

_____
<br></br>

[al INICIO](#beginning)

[VOLVER A CONTENIDOS](https://politicaygobiernopucp.github.io/estadistica_anapol2/)