

 Para ellos podemos evaluar cual de ellos seria mejor:

Creemos un vector con algunas técnicas:

```{r}
library(purrr)
# vector of methods to compare
ALL_linkages <- c( "average", "single", "complete", "ward")
names(ALL_linkages) <- c( "average", "single", "complete", "ward")

# vector:
ALL_linkages
```

La función de clusterización aglomerativa a utilizar es **agnes**. Cuando se aplica, tiene un elemento *ac* que informa qué tan bien se ha clusterizado. Voy a crear una función que me devuelva el _ac_ de cada linkage:

```{r}
# función que devuelve el ajuste:
GET_ac <- function(oneLinkage) {
  agnes(g.dist, method = oneLinkage)$ac
}
```

Ahora aplico cada _linkage_ a esa función para ir obteniendo los _ac_.
```{r}
# aplicando función 
map_dbl(ALL_linkages, GET_ac)
```

Para hacerlo facil, puedo ordenar resultado anterior:

```{r}
sort(map_dbl(ALL_linkages, GET_ac))
```






```{r, eval=FALSE}
lk="https://github.com/PoliticayGobiernoPUCP/estadistica_anapol2/raw/master/DATA/finaldemohappyurbanco2.rds"

dataMundo <- readRDS(gzcon(url(lk)))
```

```{r, eval=FALSE}
str(dataMundo)
```

```{r, eval=FALSE}
library(cluster)
g.dist = daisy(dataMundo[,-1], metric="gower")
```



```{r, eval=FALSE}
library(fpc)
pc = pamk(g.dist, krange=1:5, criterion="asw")
pc$nc
```

```{r, eval=FALSE}
hc.m = hclust(g.dist, method="median")
hc.s = hclust(g.dist, method="single")
hc.c = hclust(g.dist, method="complete")
```



```{r, eval=FALSE}
plot(hc.m)
```

```{r, eval=FALSE}
plot(hc.s)
```


```{r, eval=FALSE}
plot(hc.c)
```

Finally, we can try DBSCAN. This requires specifying two parameters: eps, the 'reachability distance' (how close two observations have to be to be linked together) and minPts (the minimum number of points that need to be connected to each other before you are willing to call them a 'cluster'). A rule of thumb for minPts is to use one more than the number of dimensions (in our case 3+1=4), but having a number that's too small isn't recommended. The default value for dbscan is 5; we'll stick with that. One way to think about the reachability distance is to see what percent of the distances are less than any given value. We can do that by examining the distribution of the distances:

```{r, eval=FALSE}
layout(matrix(1:2, nrow=1))
  plot(density(na.omit(g.dist[upper.tri(g.dist)])), main="kernel density")
  plot(ecdf(g.dist[upper.tri(g.dist)]), main="ECDF")
```

```{r, eval=FALSE}
dbc3 = dbscan(g.dist, eps=.13, MinPts=5, method="dist");  dbc3

dbc2 = dbscan(g.dist, eps=.135, MinPts=5, method="dist");  dbc2

dbc4 = dbscan(g.dist, eps=.1, MinPts=5, method="dist");  dbc4

```


```{r, eval=FALSE}
library(factoextra)

factoextra::fviz_cluster(dbc4,data = dataMundo[,-1],geom = "point")
```

gower: https://rstudio-pubs-static.s3.amazonaws.com/423873_adfdb38bce8d47579f6dc916dd67ae75.html
https://towardsdatascience.com/hierarchical-clustering-on-categorical-data-in-r-a27e578f2995

http://www.sthda.com/english/wiki/wiki.php?id_contents=7940

https://github.com/mhahsler/dbscan

https://rpubs.com/kalipradeep/dbscan

https://stats.stackexchange.com/questions/130974/how-to-use-both-binary-and-continuous-variables-together-in-clustering

https://rpkgs.datanovia.com/factoextra/reference/fviz_cluster.html

http://www.sthda.com/english/wiki/print.php?id=246
