<center><img src="https://github.com/PoliticayGobiernoPUCP/estadistica_anapol2/raw/master/PICS/LOGO_PUCP.png" width="500"></center>

<center> <header><h1>ESTADISTICA PARA EL ANALISIS POLITICO II</h1>  </header></center>

* Profesor:  <a href="http://www.pucp.edu.pe/profesor/jose-manuel-magallanes/" target="_blank">Dr. José Manuel Magallanes, Ph.D.</a> <br>
    - Profesor del Departamento de Ciencias Sociales, Sección de Ciencia Política y Gobierno.
    - [Oficina 105](https://goo.gl/maps/xuGeG6o9di1i1y5m6) - Edificio CISEPA / ECONOMIA / CCSS
    - Telefono: (51) 1 - 6262000 anexo 4302
    - Correo Electrónico: [jmagallanes@pucp.edu.pe](mailto:jmagallanes@pucp.edu.pe)
    

____

<center> <header><h2>Leyendo Data desde R</h2>  </header></center>
____

<a id='beginning'></a>

El primer paso para realizar cualquier tipo de análisis es tener los datos. Esto condiciona además el diseño de la investigación. Revisaremos los siguientes casos:

1. [Propietary software.](#part1) 
2. [Uso de APIs.](#part3) 
3. ['Scraping' tablas de datos.](#part4) 

Los datos pueden estar en algun lugar de la web; si crees que esos datos permanecerán en ese sitio, quizás puedas sólo utilizar su link de descarga y leerlos directamente. Lo más seguro, en todo caso, es usarlos de esa manera y luego guardar esa data en tu **repositorio** del proyecto (en la 'nube'). Esto facilitará su lectura y **replicabilidad**. 

Si por alguna razón deseas leerlos desde tu computadora, debes tener los archivos en la misma carpeta de tu R Notebook.


____


<a id='part1'></a>

## Data de 'proprietary software'

* Leyendo STATA:

La encuesta LAPOP está en la web. Varios años son de libre acceso, pero podemos guardar una copia en GitHub, y leer esa copia desde ahí:
```{r, eval=FALSE}
library(rio)
lkDTA="https://github.com/PoliticayGobiernoPUCP/estadistica_anapol2/raw/master/DATA/lapop2012.dta"
dataStata=import(lkDTA)
```

Para verificar qué tenemos, podemos ver la ventana *Environment*, o pedir un reporte sencillo:

```{r, eval=FALSE}
dim(dataStata) #filas, columnas
```


Toda data debe tener una guía metodologica o una descripción de las columnas (_metadata_) en su web original. Es bueno copiar y mantener una copia de esos materiales en tu proyecto. 

La librería **rio** es muy versatil, y permite con el mismo comando **import()** abrir otros tipos de archivos, como veremos a continuación.

* Leyendo SPSS:

Abramos el mismo archivo de LAPOP, pero en SPSS:

```{r, eval=FALSE}
lkSAV="https://github.com/PoliticayGobiernoPUCP/estadistica_anapol2/raw/master/DATA/lapop2012.sav"
dataSpss=import(lkSAV)
```

Verificando:
```{r, eval=FALSE}
dim(dataSpss) #filas, columnas
```

* Leyendo Excel:

El mismo archivo, pero en EXCEL:

```{r, eval=FALSE}
lkXLSX="https://github.com/PoliticayGobiernoPUCP/estadistica_anapol2/raw/master/DATA/lapop2012.xlsx"
dataExcel=import(lkXLSX)
```

Verificando:

```{r, eval=FALSE}
dim(dataExcel) #filas, columnas
```

* Leyendo CSV:

Si la data está en CSV, podemos usar _rio_, y también la función del R básico:

```{r, eval=FALSE}

lkCSV="https://github.com/PoliticayGobiernoPUCP/estadistica_anapol2/raw/master/DATA/lapop2012.csv"
dataCSV=import(lkCSV)
```

Verificando:

```{r, eval=FALSE}
dim(dataCSV) #filas, columnas
```

* Archivos de GoogleDoc

Podemos muchas veces usar los formularios de Google Docs para recoger información. Estos formularios dejan la información en una hoja de calculo de google (GoogleSheet). Si Ud publica esa data como archivo tipo CSV, use el comando anterior.

**EJERCICIO**. Cree un cuestionario usando GoogleForms y descargue las respuestas en R.

* Archivos de Datos Espaciales

En este [link](https://app.box.com/s/mdcqfue3u0wis0b3v4gy0kwcjv4e0amu) encontrarás una carpeta comprimida. Al descomprimirla, encontraras varios _tipos_ de archivos con el mismo _nombre_. Eso constituye un mapa en formato **SHAPEFILE**. Es dificil que R lea este mapa, por lo que debes convertirlo a formato **topojson**. 

**EJERCICIO**. Cambie el mapa a formato **JSON**. Para ello vaya al [mapshaper](https://mapshaper.org/); desde ahí, suba los archivos de la carpeta, simplifiquelo, y luego exportelo como _topojson_. Luego, suba el archivo _topojson_ a Github; guarde el link de descarga del archivo subido; y abralo en R así:

```{r, eval=FALSE}
# instalar:
library(sp)
library(geojsonio)
library(rgdal)

fromGit="XXXXX" # link desde github

wazipMap <- rgdal::readOGR(fromGit,stringsAsFactors = FALSE)
plot(wazipMap)
```

[al INICIO](#beginning)


-----

<a id='part3'></a>

## Uso de los APIs

Hay organizaciones que tiene una política de datos abiertos, por lo que ofrecen un portal ad-hoc para que se pueda acceder a sus datos. La data es recogida, por lo general, en formato  XML o JSON. 

Los API permiten construir pedidos de datos a través de una dirección web. Para que el trabajo de colección de datos sea exitoso, necesitamos revisar la documentación del API.

Por ejemplo, la Municipalidad de San Isidro tiene un [portal de datos abiertos](http://datosabiertos.msi.gob.pe/home). En este caso accederemos a los datos de Seguridad Ciudadana, siguiendo el [link](http://datosabiertos.msi.gob.pe/dashboards/9238/seguridad-ciudadana-y-fiscalizacion/) ofrecido en el portal. Cuando se accede, se ven dos tablas de datos; si selecciona *intervenciones de serenazgo* verá sólo esa tabla.

A la izquierda hay unos íconos, si presiona el que tiene apariencia de un 'engranaje', verá lo siguiente:

<img src="https://github.com/PoliticayGobiernoPUCP/estadistica_anapol2/raw/master/PICS/API_msi.png" width="500">

Lo primero que te sugiere el API es que obtengas tu **llave** (API_KEY). Consigue una y guardala como objeto:
```{r, eval=FALSE}
miLLAVE='e309f64f37e50c0893da23a36d9165f0fd182e39'
```

Luego, te indica que construyas una solicitud para colectar los datos que están en la _vista de datos_ actual (GUID), incluyendo el formato:

```{r, eval=FALSE}
GUID='http://api.datosabiertos.msi.gob.pe/api/v2/datastreams/INTER-DE-SEREN-2019/'
FORMATO='data.json/'
```

Entonces, tu solicitud se arma así:
```{r, eval=FALSE}
request=paste0(GUID,FORMATO,'?auth_key=',miLLAVE)

#mirala
request
```


R necesita que instales **jsonlite** para poder interpretar formato JSON; luego de hacerlo, habilitala
```{r, eval=FALSE}
library(jsonlite) 
```

De aquí, ya podrias colectar la data:

```{r, eval=FALSE}
serenosSI = fromJSON(request)

#miralo
serenosSI
```

Este pedido no se parece a lo que necesitas. No es que hayas fracasado, sino que debiste estudiar la documentación del API, disponible [aquí](https://junar.github.io/docs/es/). Luego de leerla, sabrías que era mejor pedir otro formato para la **[vista](https://junar.github.io/docs/es/_sections/04-vistas.html)** de datos, el PJSON:
```{r, eval=FALSE}
FORMATO='data.pjson/'
request2=paste0(GUID,FORMATO,'?auth_key=',miLLAVE)
```

Usemos la nueva solicitud:
```{r, eval=FALSE}
serenosSI = fromJSON(request2)
```

Veamos su estructura:

```{r, eval=FALSE}
str(serenosSI)
```

Para acceder a los datos en formato tabla de esa solicitud, debemos acceder al elemento **result**:

```{r, eval=FALSE}
head(serenosSI$result)
```

Lo que hemos recolectado son:
```{r, eval=FALSE}
dim(serenosSI$result)
```

Será es la cantidad total de intervenciones? Si seguimos leyendo la documentación, aprenderemos que hay varios [parametros](https://junar.github.io/docs/es/_sections/07-estadisticas.html#) disponibles para mejorar la busqueda:

```{r, eval=FALSE}
Parametros='&from=01/01/2010'
request3=paste0(GUID,FORMATO,'?auth_key=',miLLAVE,Parametros)
serenosSI_all = fromJSON(request3)$result
```

Aquí confirmamos lo que hay disponible en total:
```{r, eval=FALSE}
dim(serenosSI_all)
```

**Ejercicio**. Traer los datos de los últimos 15 días.

[al INICIO](#beginning)

----


<a id='part4'></a>


##‘Scraping’ tablas de datos

Las tablas de datos en la web pueden ser descargadas con facilidad, si se consigue identificar la ruta hacia ella. Cuando identifiques una tabla que te interesa, usa el botón derecho de tu mouse para inspeccionar el código de la página web. Usa la opción inspección hasta que **resalte toda** la tabla.

Por ejemplo, visita este [link](https://www.nationsonline.org/oneworld/corruption.htm). Estando en esa página usando **GoogleChrome** ubicate en la tabla e inspecciona usando el boton derecho:

<img src="https://github.com/PoliticayGobiernoPUCP/estadistica_anapol2/raw/master/PICS/scrap1.png" width="700">

Debes seguir _inspeccionando_ hasta que se resalte tu tabla:

<img src="https://github.com/PoliticayGobiernoPUCP/estadistica_anapol2/raw/master/PICS/scrap2.png" width="700">

Nota que en este caso tienes varias tablas, debes ser muy preciso en tu selección. Una vez haya identificado bien tu tabla, usa nuevamente el boton derecho sobre el código en _html_ y copia el **XPATH**. Nota que a veces es más util copiar el XPATH del cuerpo de la tabla (**body**), en vez que la tabla.

<img src="https://github.com/PoliticayGobiernoPUCP/estadistica_anapol2/raw/master/PICS/scrap3.png" width="700">

Hasta aqui tienes:

```{r, eval=FALSE}
linkPage="https://www.nationsonline.org/oneworld/corruption.htm" 
linkPath = "/html/body/table[3]" 
```

Para traer los datos, debes instalar **htmltab**, y luego ya usar este código:

```{r, eval=FALSE}
library(htmltab)
corrupcion = htmltab(doc = linkPage, 
                     which =linkPath) 
```

Esto es lo que tienes:

```{r, eval=FALSE}
head(corrupcion)
```

Nota lo que hay al final:

```{r, eval=FALSE}
tail(corrupcion)
```


La data mas _sucia_ es la que se obtiene por esta vía; y tienes que evitar traer más 'suciedad' cuando puedas. Ayudará en algo usar el XPATH del **body** de la tabla?

**Ejercicio**. Traer los datos usando el XPATH del **body** de la tabla, y verificar si era una mejor alternativa o no.

_____
<br></br>

[al INICIO](#beginning)

####[VOLVER A CONTENIDOS](https://politicaygobiernopucp.github.io/estadistica_anapol2/)